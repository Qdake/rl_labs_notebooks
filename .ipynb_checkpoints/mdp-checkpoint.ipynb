{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "##########-action constants-###################\n",
    "N = 0\n",
    "S = 1\n",
    "E = 2\n",
    "W = 3\n",
    "NOOP = 4  \n",
    "\n",
    "\n",
    "def discreteProb(p):\n",
    "        # Draw a random number using probability table p (column vector)\n",
    "        # Suppose probabilities p=[p(1) ... p(n)] for the values [1:n] are given, sum(p)=1 \n",
    "        # and the components p(j) are nonnegative. \n",
    "        # To generate a random sample of size m from this distribution,\n",
    "        #imagine that the interval (0,1) is divided into intervals with the lengths p(1),...,p(n). \n",
    "        # Generate a uniform number rand, if this number falls in the jth interval given the discrete distribution,\n",
    "        # return the value j. Repeat m times.\n",
    "        r = np.random.random()\n",
    "        cumprob=np.hstack((np.zeros(1),p.cumsum()))\n",
    "        sample = -1\n",
    "        for j in range(p.size):\n",
    "            if (r>cumprob[j]) & (r<=cumprob[j+1]):\n",
    "                sample = j\n",
    "                break\n",
    "        return sample\n",
    "\n",
    "def softmax(Q,x,tau):\n",
    "    # Returns a soft-max probability distribution over actions\n",
    "    # Inputs :\n",
    "    # - Q : a Q-function represented as a nX times nU matrix\n",
    "    # - x : the state for which we want the soft-max distribution\n",
    "    # - tau : temperature parameter of the soft-max distribution\n",
    "    # Output :\n",
    "    # - p : probability of each action according to the soft-max distribution\n",
    "    \n",
    "    p = np.zeros((len(Q[x])))\n",
    "    sump = 0\n",
    "    for i in range(len(p)) :\n",
    "        p[i] = np.exp((Q[x,i]/tau).round(5))\n",
    "        sump += p[i]\n",
    "    \n",
    "    p = p/sump\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "def compare(V,Q,pol): \n",
    "    # compares the state value V with the state-action value Q following policy pol\n",
    "    epsilon = 0.01 # precision of the comparison\n",
    "    sumval = np.zeros((V.size))\n",
    "    for i in range(V.size): # compute the difference between V and Q for each state\n",
    "        sumval[i] = abs(V[i] - Q[i,pol[i]])\n",
    "         \n",
    "    if np.max(sumval)<epsilon :\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.table import Table\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "\n",
    "###################-plot functions for a maze like environment-#################\n",
    "\n",
    "\n",
    "##################################################\n",
    "\n",
    "#### maze_mdp plot, used to plot the agent in its environment while processing the V/Q function and policy \n",
    "#### it can also create videos given a list of V/Q values and a list of policies\n",
    "\n",
    "class maze_plotter():\n",
    "    def __init__(self, maze, terminal_states): # maze defined in the mdp notebook\n",
    "        self.maze_attr = maze\n",
    "        self.terminal_states = terminal_states\n",
    "        plt.ion()\n",
    "        self.figW = self.maze_attr.width\n",
    "        self.figH = self.maze_attr.height\n",
    "        self.figure_history=[]\n",
    "        self.axes_history=[]\n",
    "        self.table_history=[]\n",
    "        self.agent_patch_history = []\n",
    "        \n",
    "    def init_table(self): # the states of the mdp are drawn in a matplotlib table, this function creates this table\n",
    "        \n",
    "        width = 1 #0.1\n",
    "        height = 1 #0.2\n",
    "        \n",
    "        for i in range(self.maze_attr.height) :\n",
    "            for j in range(self.maze_attr.width) :\n",
    "                state = j*self.maze_attr.height + i\n",
    "                color = np.zeros(3)\n",
    "                if state in self.maze_attr.walls :\n",
    "                    color[0]=color[1]=color[2]=0\n",
    "                else :\n",
    "                    color[0]=color[1]=color[2]=1\n",
    "                self.table_history[-1].add_cell(i,j, width, height, facecolor=color, text='', loc='center')\n",
    "        \n",
    "        self.axes_history[-1].add_table(self.table_history[-1])\n",
    "    \n",
    "    def new_render(self): # initializes the plot by creating its basic components (figure, axis, agent patch and table)\n",
    "        # a trace of these components is stored so that the old outputs will last on the notebook \n",
    "        # when a new rendering is performed\n",
    "        self.figure_history.append(plt.figure(figsize=(self.figW,self.figH)))\n",
    "        self.axes_history.append(self.figure_history[-1].add_subplot(111)) # 111 : number of rows, columns and index of subplot\n",
    "        self.table_history.append(Table(self.axes_history[-1], bbox=[0,0,1,1])) # [left, bottom, width, height]\n",
    "        self.agent_patch_history.append(mpatches.Ellipse((-1,-1), 0.06, 0.085, ec=\"none\", fc=\"dodgerblue\", alpha=0.6))\n",
    "        self.axes_history[-1].add_patch(self.agent_patch_history[-1])\n",
    "        self.init_table()\n",
    "\n",
    "    def coords(self, height, width, state): #processes the starting position of the arrows\n",
    "        i = state%self.maze_attr.height\n",
    "        j = int(state/self.maze_attr.height)\n",
    "        h = 1/self.figH\n",
    "        ch = h/2\n",
    "        w = 1/self.figW\n",
    "        cw = w/2\n",
    "        x,y = j*w + cw,1-(i*h + ch)\n",
    "        return x,y\n",
    "    \n",
    "    def render(self, agent_state=-1, V=[], policy=[], render=True): # updates the values of the table \n",
    "        # and the agent position and current policy \n",
    "        # some of these components may not show depending on the parameters given when calling this function\n",
    "        if len(self.figure_history) == 0 : # new plot\n",
    "            self.new_render()\n",
    "        \n",
    "       \n",
    "        self.axes_history[-1].clear()\n",
    "        self.axes_history[-1].add_table(self.table_history[-1])\n",
    "        \n",
    "        #### Table values and policy update\n",
    "        if len(V)>0: # working with state values\n",
    "            if len(V.shape)==1 :\n",
    "                self.V_render(agent_state, V, policy, render) \n",
    "            else : # working with state values\n",
    "                self.Q_render(agent_state, V, policy, render)\n",
    "\n",
    "        \n",
    "        if agent_state >= 0:\n",
    "            x,y = self.coords(self.maze_attr.height, self.maze_attr.width, agent_state)\n",
    "            \n",
    "            \n",
    "            self.agent_patch_history[-1].center = x,y\n",
    "    \n",
    "            self.axes_history[-1].add_patch(self.agent_patch_history[-1])\n",
    "            #print(agent_state,i,x,j,y)\n",
    "        \n",
    "        #plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        if render :\n",
    "            self.figure_history[-1].canvas.draw()\n",
    "            self.figure_history[-1].canvas.flush_events()\n",
    "        return self.figure_history[-1]\n",
    "    \n",
    "    \n",
    "    def V_render(self, agent_state, V, policy, render):\n",
    "        \n",
    "        for i in range(self.maze_attr.height) :\n",
    "            for j in range(self.maze_attr.width):\n",
    "                state = j*self.maze_attr.height + i\n",
    "                color = np.zeros(3)\n",
    "                if state in self.maze_attr.walls:\n",
    "                    color[0]=color[1]=color[2]=0\n",
    "                else:\n",
    "                    color[0]=color[1]=color[2]=np.min([1-V[state]/(np.max(V)+1),1])\n",
    "                    \n",
    "                self.table_history[-1]._cells[(i,j)].set_facecolor(color)\n",
    "\n",
    "                self.table_history[-1]._cells[(i,j)]._text.set_text(np.round(V[state],2))\n",
    "                \n",
    "                if len(policy)>0 and not (state in self.maze_attr.walls or state in self.terminal_states):\n",
    "                    x0, y0, x,y = self.arrow_params(self.maze_attr.height, self.maze_attr.width,\n",
    "                                                        state, policy[state])\n",
    "                    arw_color = \"red\"\n",
    "                    alpha = 0.6\n",
    "                        \n",
    "                    if not(x == y and x == 0):\n",
    "                        self.axes_history[-1].arrow(x0, y0, x, y, alpha=alpha,\n",
    "                                      head_width=0.03, head_length=0.03, fc=arw_color, ec=arw_color)\n",
    "        \n",
    "        \n",
    "    def Q_render(self, agent_state, Q, policy, render):\n",
    "         \n",
    "        for i in range(self.maze_attr.height) :\n",
    "            for j in range(self.maze_attr.width):\n",
    "                \n",
    "                state = j*self.maze_attr.height + i\n",
    "                color = np.zeros(3)\n",
    "                if state in self.maze_attr.walls:\n",
    "                    color[0]=color[1]=color[2]=0\n",
    "                else:\n",
    "                    color[0]=color[1]=color[2]=np.min([1-np.max(Q[state])/(np.max(Q)+1),1])\n",
    "                    \n",
    "                self.table_history[-1]._cells[(i,j)].set_facecolor(color)\n",
    "\n",
    "                self.table_history[-1]._cells[(i,j)]._text.set_text(np.round(np.max(Q[state]),2))\n",
    "                \n",
    "                if not (state in self.maze_attr.walls or state in self.terminal_states):\n",
    "                    qmin = np.min(Q[state])\n",
    "                    if qmin < 0:\n",
    "                        qmin *= -1\n",
    "                    pos_Q = Q[state] + qmin\n",
    "                    qmax = np.max(pos_Q)\n",
    "                    norm_Q = pos_Q / (np.sum(pos_Q)-(list(pos_Q).count(qmax)*qmax)+0.1)\n",
    "                    \n",
    "                    \n",
    "                    for action in range(len(Q[state])):\n",
    "                        \n",
    "                        x0, y0, x, y = self.qarrow_params(self.maze_attr.height, \n",
    "                                                    self.maze_attr.width, state, action)\n",
    "\n",
    "\n",
    "                        arw_color = \"green\"\n",
    "                        alpha = 0.9\n",
    "                        qmax = np.max(Q[state])\n",
    "\n",
    "                        if not Q[state][action]==qmax:\n",
    "                            arw_color = \"red\"\n",
    "                            alpha = norm_Q[action]\n",
    "\n",
    "                        if x == 0 and y == 0:\n",
    "                            circle = mpatches.Circle((x0, y0), 0.02, ec=arw_color, fc=arw_color, alpha=alpha)\n",
    "                            self.axes_history[-1].add_patch(circle)\n",
    "                        else:\n",
    "                            self.axes_history[-1].arrow(x0, y0, x, y, alpha=alpha,\n",
    "                                          head_width=0.03, head_length=0.02, fc=arw_color, ec=arw_color)\n",
    "\n",
    "\n",
    "\n",
    "           \n",
    "    def arrow_params(self, height, width, state, action): #processes the starting position of the arrows\n",
    "        x,y= self.coords(height, width, state)\n",
    "        \n",
    "        if action == N :\n",
    "            return [x, y+0.02, 0.0, 0.04]\n",
    "        elif action == S :\n",
    "            return [x, y-0.02, 0.0, -0.04]\n",
    "        elif action == W :\n",
    "            return [x-0.03, y, -0.02, 0.0]\n",
    "        elif action == E :\n",
    "            return [x+0.03, y, 0.02, 0.0]\n",
    "        else :\n",
    "            return [x, y, 0.0, 0.0]   \n",
    "    \n",
    "    def qarrow_params(self, height, width, state, action): #processes the starting position of the arrows\n",
    "        x,y= self.coords(height, width, state)\n",
    "        \n",
    "        if action == N :\n",
    "            return [x, y+0.03, 0.0, 0.0125] #1/(10*self.figH)]\n",
    "        elif action == S :\n",
    "            return [x, y-0.03, 0.0, -1/(10*self.figH)]\n",
    "        elif action == W :\n",
    "            return [x-0.03, y, -1/(10*self.figW), 0.0]\n",
    "        elif action == E :\n",
    "            return [x+0.03, y, 1/(10*self.figW), 0.0]\n",
    "        else :\n",
    "            return [x, y, 0.0, 0.0]   \n",
    "        \n",
    "        \n",
    "    def save_fig(self, title):\n",
    "        self.figure_history[-1].savefig(title)\n",
    "        \n",
    "    def update(self, frame, V_list, pol_list):\n",
    "        if len(pol_list)>frame:\n",
    "            return self.render(V=V_list[frame],policy=pol_list[frame], render=False)\n",
    "        else:\n",
    "            return self.render(V=V_list[frame], render=False)\n",
    "    \n",
    "    def create_animation(self, Q_list=[], pol_list=[], nframes=0):\n",
    "        new_Qlist = Q_list\n",
    "        new_polist = pol_list\n",
    "        if nframes > 0 :\n",
    "            new_Qlist, new_polist = self.resize_lists(Q_list, pol_list, nframes)\n",
    "            \n",
    "        self.new_render()\n",
    "        anim = animation.FuncAnimation(self.figure_history[-1], self.update, frames=len(new_Qlist), \n",
    "                                       fargs=[new_Qlist, new_polist], blit=True)\n",
    "        #plt.close()\n",
    "        return anim\n",
    "    \n",
    "    def resize_lists(self, Q_list, policy_list, nb_frames): #gets samples from the data list to fit the number of frames \n",
    "        # to show in the animation\n",
    "        # used when the length of the data list exceeds the number of the frames required for the video\n",
    "                    \n",
    "        if nb_frames < len(Q_list) :\n",
    "            step = np.int(np.round(len(Q_list)/nb_frames,0))\n",
    "            print(\"sample length : \",len(Q_list))\n",
    "            print(\"nb of frames : \",nb_frames)\n",
    "            print(\"step size : \",step)\n",
    "\n",
    "            new_Qlist = []\n",
    "            new_polist = []\n",
    "\n",
    "            for i in range(0,len(Q_list),step) :\n",
    "                new_Qlist.append(Q_list[i])\n",
    "                if len(policy_list) > i:\n",
    "                    new_polist.append(policy_list[i])            \n",
    "\n",
    "            return new_Qlist, new_polist\n",
    "        else :\n",
    "            return Q_list, policy_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes simple_actspace, mdp, maze, maze_mdp\n",
    "\n",
    "The code below provides the classes to represent environments to evaluate various dynamic programming (DP) and reinforcement learning (RL) algorithms. \n",
    "\n",
    "The code to display the effect of the algorithms in these environment is in [maze_plotter.ipynb](maze_plotter.ipynb).\n",
    "\n",
    "A Markov Decision Process describes the environment. It is a tuple $(S, A, P, r, \\gamma)$ where \n",
    "* $S$ is the state space, \n",
    "* $A$ the action space,\n",
    "* $P(state_t,  action_t, state_{t+1})$ the transition function, \n",
    "* $r(state_t, action_t)$ the reward function and $\\gamma \\in [0, 1]$ the discount factor.\n",
    "\n",
    "In our maze environment, \n",
    "* the states are the different cells of the grid,\n",
    "* the possible actions for the agent are going north, south, east or west (resp. [0,1,2,3]).\n",
    "\n",
    "* In addition to the transition function, we have an additional distribution $P_0$ that defines the distribution of the first state. By default, it is set to 1.0 in state 0 and 0.0 in the rest of the states\n",
    "* With the deterministic transition function defined here, the actions always lead to the same outcome, so going north always leads up, unless the agent is on one of the top states or the cell above is a wall, in which case the agent stays at the same state. \n",
    "* The reward function consists of a matrix of shape (state, action).\n",
    "\n",
    "In practice,\n",
    "* when launching an episode, using the __reset()__ gives the first state according to either $P_0$ probabilities over all the states.\n",
    "* Once initialization is over, use of __step(u)__ which, given an action $u$, draws the next state according to the distribution $P$ and returns it along with several things: \n",
    "* the reward of this step, \n",
    "* a boolean stating if the episode is over (either because the agent found itself in a terminal state or because the timeout has been reached) and \n",
    "* few information that can be used when debugging.\n",
    "\n",
    "In order to visualize the environment \n",
    "* use __new_render()__ function to initialize the rendering, \n",
    "* then __render(V, policy, agent_pos)__ to refresh the maze with either the newly calculated V and the policy, or the Q values, and the current position of the agent. \n",
    "* The function __save_fig(title)__ is used to save into disk the last render.\n",
    "\n",
    "you can generate a video (animation) of your results:\n",
    "* Given a list of the different V or Q values, a list of policies, and the number of your frames, you can generate a video (animation) of your results using the function __create_animation()__. \n",
    "It is particularly useful in the RL functions, where the number of episodes is high and outputting the results during the process makes it last longer. \n",
    "\n",
    "Whenever you want to show something on your notebook, use the magic __%matplotlib notebook__ at the beginning of your cell, or just __%matplotlib__ if you want the output to be done on a separate window.\n",
    "\n",
    "You can see an example of these different output methods in the Q-Learning results visualization implemented in the [reinforcement_learning.ipynb](reinforcement_learning.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "    \n",
    "class simple_actspace(): #class describing the action space of the markov decision process\n",
    "    def __init__(self, action_list=[], nactions=0):\n",
    "        if len(action_list) == 0:\n",
    "            self.actions = np.array([a for a in range(nactions)])\n",
    "        else:\n",
    "            self.actions = action_list\n",
    "            \n",
    "        self.size = len(self.actions)\n",
    "        \n",
    "    def sample(self, prob_list=None): #returns an action drawn according to the prob_list distribution, \n",
    "        # if the param is not set, then it is drawn from a uniform distribution \n",
    "        if prob_list is None :\n",
    "            prob_list = np.ones((self.size))/self.size\n",
    "            \n",
    "        index = discreteProb(prob_list) \n",
    "        return  self.actions[index]\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "class mdp(): #defines a Markov Decision Process\n",
    "\n",
    "    def __init__(self, observation_space, action_space, start_distribution, transition_matrix,\n",
    "                  reward_matrix, plotter, gamma=0.9, terminal_states=[], timeout=50):\n",
    "        \n",
    "        self.observation_space = observation_space\n",
    "        self.terminal_states = terminal_states\n",
    "        self.action_space = action_space\n",
    "        self.current_state = -1 #current position of the agent in the maze, it's set by the method reset()\n",
    "        self.timeout = timeout #maximum length of an episode\n",
    "        self.timestep = 0 \n",
    "        self.P0 = start_distribution #distribution used to draw the first state of the agent, used in method reset()\n",
    "        self.P = transition_matrix\n",
    "        self.r = reward_matrix\n",
    "        self.plotter = plotter #used to plot the maze\n",
    "        self.gamma = gamma #discount factor\n",
    "        self.last_action_achieved = False #used to tell whether the last state has been reached or not (see done())\n",
    "    \n",
    "    \n",
    "\n",
    "    def reset(self, uniform=False): #initializes an episode and returns the state of the agent\n",
    "        #if uniform is set to False, the first state is drawn according to the P0 distribution, \n",
    "        #else it's drawn on a uniform distribution over all the states\n",
    "        \n",
    "        if uniform :\n",
    "            prob = np.ones((self.observation_space.size))/self.observation_space.size\n",
    "            self.current_state = discreteProb(prob)\n",
    "        else :\n",
    "            self.current_state = discreteProb(self.P0)\n",
    "            \n",
    "        self.timestep = 0\n",
    "        self.last_action_achieved = False\n",
    "        \n",
    "        return self.current_state\n",
    " \n",
    "    \n",
    "    def step(self,u,deviation=0): # performs a step forward in the environment, \n",
    "        # if you want to add some noise to the reward, give a value to the deviation param \n",
    "        # which represents the mean μ of the normal distribution used to draw the noise \n",
    "        \n",
    "        if np.random.random() < 0.15:\n",
    "            temp = list(range(4));\n",
    "            temp.remove(u);\n",
    "            u = np.random.choix(temp);\n",
    "        \n",
    "        noise = 0 # = deviation*np.random.randn() # generate noise, see an exercize in mbrl.ipynb\n",
    "        reward = self.r[self.current_state,u] +noise # r is the reward of the transition, you can add some noise to it \n",
    "        \n",
    "        # the state reached when performing action u from state x is sampled \n",
    "        # according to the discrete distribution self.P[x,u,:]\n",
    "        observation = discreteProb(self.P[self.current_state,u,:]) \n",
    "        \n",
    "        self.timestep += 1 \n",
    "        \n",
    "        \n",
    "        info = {} #can be used when debugging\n",
    "        info[\"State transition probabilities\"] = self.P[self.current_state,u,:]\n",
    "        info[\"reward's noise value\"] = noise\n",
    "        \n",
    "        self.current_state = observation\n",
    "        done = self.done() #checks if the episode is over\n",
    "        \n",
    "        return [observation,reward,done,info]\n",
    "    \n",
    "    \n",
    "    def done(self): #returns True if the episode is over\n",
    "        if self.last_action_achieved :\n",
    "            return True\n",
    "        if self.current_state in self.terminal_states: #done when a terminal state is reached\n",
    "            #the terminal states are actually a set of states from which any action leads to an added imaginary state, \n",
    "            #the \"well\", with a reward of 1. To know if the episode is over, we have to check\n",
    "            #whether the agent is on one of these last states and performed the action that gives it its last reward \n",
    "            self.last_action_achieved = True\n",
    "            \n",
    "        return self.timestep == self.timeout #done when timeout reached\n",
    "    \n",
    "    \n",
    "    def new_render(self): #initializes a new environment rendering (a plot defined by a figure, an axis...)\n",
    "        self.plotter.new_render()\n",
    "    \n",
    "    def render(self, V=[], policy=[], agent_pos=-1): #outputs the agent in the environment with values V (or Q)\n",
    "        \n",
    "        if agent_pos > -1:\n",
    "            self.plotter.render(agent_state=agent_pos, V=V, policy=policy)\n",
    "        elif self.current_state > -1:# and not self.last_action_achieved:\n",
    "            self.plotter.render(agent_state=self.current_state, V=V, policy=policy)\n",
    "        else :\n",
    "            self.plotter.render(V=V, policy=policy)\n",
    "        \n",
    "    def save_fig(self, title): #saves the current output into the disk\n",
    "        self.plotter.save_fig(title)\n",
    "            \n",
    "    def create_animation(self,V_list=[],policy_list=[],nframes=0): #given a list of V or Q values, a list of policies, \n",
    "        # and eventually the number of frames wanted, it generates a video of the different steps\n",
    "        return self.plotter.create_animation(V_list,policy_list,nframes)\n",
    "    \n",
    "\n",
    "class maze(): #describes a maze-like environment\n",
    "    def __init__(self, width, height, walls=[]):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.states = np.array([s for s in range(width*height)])\n",
    "        self.walls = walls\n",
    "        self.size = width*height\n",
    "     \n",
    "\n",
    "    \n",
    "class maze_mdp(mdp): #defines a Markov Decision Process which observation space is a maze\n",
    "\n",
    "    def __init__(self, width, height, walls=[], action_list=[], nactions=4,\n",
    "                 gamma=0.9, timeout=50, start_states=[0], terminal_states=[]):\n",
    "        #width, height : int numbers defining the maze attributes\n",
    "        #walls : list of the states that represent walls in our maze environment\n",
    "        #action_list : list of possible actions\n",
    "        #nactions : used when action_list is empty, by default there are 4 of them (go north, south, eat or west)\n",
    "        #gamma : the discount factor of our mdp\n",
    "        #timeout : defines the length of an episode (max timestep) --see done() function\n",
    "        #start_states : list that defines the states where the agent can be at the beginning of an episode\n",
    "        #terminal_states : list that defines the states corresponding to the end of an episode\n",
    "        #                  (agent reaches a terminal state) --cf. done() function\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###################### State Space ######################\n",
    "        \n",
    "        observation_space = maze(width, height, walls)\n",
    "        \n",
    "        ###################### Action Space ######################\n",
    "        \n",
    "        action_space = simple_actspace(action_list=action_list, nactions=nactions)    \n",
    "        \n",
    "        \n",
    "        ###################### Distribution Over Initial States ######################\n",
    "        \n",
    "        start_distribution = np.zeros((observation_space.size)) #distribution over initial states\n",
    "        \n",
    "        for state in start_states:\n",
    "            start_distribution[state] = 1.0/len(start_states)\n",
    "\n",
    "        ###################### Transition Matrix ######################\n",
    "        \n",
    "        transition_matrix = np.empty((observation_space.size+1,action_space.size,observation_space.size+1)) #a \"well\" state is added that only the terminal states can get into\n",
    "        \n",
    "        # Transition Matrix when going north\n",
    "        transition_matrix[:,N,:] = np.zeros((observation_space.size+1,observation_space.size+1))\n",
    "        for i in observation_space.states : \n",
    "            if i == 0 or i%observation_space.height == 0 or i-1 in observation_space.walls or i in observation_space.walls: #the state doesn't change (highest cells + cells under a wall)\n",
    "                transition_matrix[:,N,:][i][i] = 1.0\n",
    "            else : #it goes up\n",
    "                transition_matrix[:,N,:][i][i-1] = 1.0\n",
    "        \n",
    "        # Transition Matrix when going south\n",
    "        transition_matrix[:,S,:] = np.zeros((observation_space.size+1,observation_space.size+1))\n",
    "        for i in observation_space.states : \n",
    "            if i%observation_space.height == observation_space.height-1 or i+1 in observation_space.walls or i in observation_space.walls: #the state doesn't change (lowest cells + cells above a wall)\n",
    "                transition_matrix[:,S,:][i][i] = 1.0\n",
    "            else : #it goes down\n",
    "                transition_matrix[:,S,:][i][i+1] = 1.0\n",
    "    \n",
    "        #self.P[:,S,:][49][50] = 0.2 #example for hacking local probabilities\n",
    "        #self.P[:,S,:][49][48] = 0.8\n",
    "\n",
    "\n",
    "        # Transition Matrix when going west\n",
    "        transition_matrix[:,W,:] = np.zeros((observation_space.size+1,observation_space.size+1))\n",
    "        for i in observation_space.states : \n",
    "            if i<observation_space.height or i-observation_space.height in observation_space.walls or i in observation_space.walls: #state doesn't change (cells on the right side of a wall)\n",
    "                transition_matrix[:,W,:][i][i] = 1.0\n",
    "            else : #it goes left\n",
    "                transition_matrix[:,W,:][i][i-height] = 1.0\n",
    "        \n",
    "\n",
    "        # Transition Matrix when going east\n",
    "        transition_matrix[:,E,:] = np.zeros((observation_space.size+1,observation_space.size+1))\n",
    "        for i in observation_space.states : \n",
    "            if i>observation_space.size-observation_space.height-1 or i+observation_space.height in observation_space.walls or i in observation_space.walls: #state doesn't change (cells on the left side of a wall)\n",
    "                transition_matrix[:,E,:][i][i] = 1.0\n",
    "            else : #it goes right\n",
    "                transition_matrix[:,E,:][i][i+height] = 1.0\n",
    "                \n",
    "        # Transition Matrix of final states \n",
    "        well = observation_space.size # all the final states' transitions go there\n",
    "        for s in terminal_states:\n",
    "            transition_matrix[s,:,:] = 0\n",
    "            transition_matrix[s,:,well] = 1\n",
    "            \n",
    "        \n",
    "        # Transition Matrix when not moving (action removed from the current version)\n",
    "        #transition_matrix[:,NoOp,:] = np.eye(observation_space.size)\n",
    "\n",
    "        ###################### Reward Matrix ######################\n",
    "\n",
    "        reward_matrix = np.zeros((observation_space.size, action_space.size)) \n",
    "        for s in terminal_states:\n",
    "            reward_matrix[s,:] = 1 # leaving a final state gets the agent a reward of 1\n",
    "        #reward_matrix[-1][NoOp] = 1.0\n",
    "        #reward_matrix[25][NoOp] = 0.9\n",
    "        \n",
    "        plotter = maze_plotter(observation_space, terminal_states) #renders the environment\n",
    "        mdp.__init__(self, observation_space, action_space, start_distribution, transition_matrix,\n",
    "                 reward_matrix, plotter, gamma=gamma, terminal_states=terminal_states, timeout=timeout)\n",
    "\n",
    "    \n",
    "    def reset(self, uniform=False): #initializes an episode\n",
    "        #if uniform is set to False, the first state is drawn from the P0 distribution, \n",
    "        #else it is drawn from a uniform distribution over all the states except for walls\n",
    "        if uniform:\n",
    "            prob = np.ones((self.observation_space.size))/(self.observation_space.size-len(self.observation_space.walls))\n",
    "            for state in self.observation_space.walls:\n",
    "                prob[state]= 0.0 \n",
    "            self.current_state = discreteProb(prob)\n",
    "        else :\n",
    "            self.current_state = discreteProb(self.P0)\n",
    "\n",
    "        self.timestep = 0\n",
    "        self.last_action_achieved = False\n",
    "        return self.current_state\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of using the maze_mdp class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"900\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "walls = [7,8,9,10,21,27,30,31,32,33,45,46,47]\n",
    "height = 6\n",
    "width = 9\n",
    "m = maze_mdp(width, height, walls=walls) # maze-like MDP definition\n",
    "m.render()\n",
    "#m.save_fig(\"sample_maze.png\") #used to save a picture of the maze as a png file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
